{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1a1562d-14d2-41ab-aede-4cb793faeab8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install openai==1.12.0\n",
    "%pip install tiktoken==0.6.0\n",
    "%pip install langchain==0.1.16\n",
    "%pip install langchain-openai==0.0.36\n",
    "%pip install langchain-community==0.0.33\n",
    "%pip install mlflow==2.12.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87a0e85e-c6d0-45ee-939e-4d31cf50e722",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6aba6e21-f150-45e6-ac4d-f7561411c765",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "file_path = \"/Volumes/ads-predictive-analytics/default/test/clinical_notes_dataset.csv\"  \n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d07cece6-cddd-4a23-9071-e139309e01b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Reformat clinical notes\n",
    "documents = df[[\"Patient_ID\", \"Notes\"]].astype(str).apply(lambda x: \"Patient \" + x[\"Patient_ID\"] + \": \" + x[\"Notes\"], axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "534ef647-b56a-4206-ae3e-15c988fb64c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install sentence-transformers # Initialize embeddings and vector database\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings()\n",
    "vectorstore = FAISS.from_texts(documents, embeddings)\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "81c5f88c-16d4-4c99-9a56-30bb51e551ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initialize RAG summarization model\n",
    "llm = OpenAI(model_name=\"gpt-3.5\")\n",
    "qa_chain = RetrievalQA(llm=llm, retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ee100b07-9d24-48a5-9e6d-ca4a9f723d9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create function to summarize notes using RAG\n",
    "def summarize_text_rag(text):\n",
    "    if isinstance(text, str) and len(text) > 0:\n",
    "        query = f\"Summarize the following clinical note: {text}\"\n",
    "        response = qa_chain.run(query)\n",
    "        return response\n",
    "    return \"No summary available\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b55ee3ee-4c3f-417e-a44d-688a09868115",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Apply RAG summarization to clinical notes\n",
    "df[\"Generated_Summary\"] = df[\"Notes\"].apply(summarize_text_rag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6cb42ee9-fbb9-4fdc-9360-0136129eb90c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Save the new dataset with summaries\n",
    "output_file = \"/Volumes/ads-predictive-analytics/default/test/clinical_notes_with_rag_summaries.csv\"\n",
    "df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b7d5eba0-34df-4421-8bd8-5223aad659cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Summarized clinical notes saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1984b4c0-763b-42a9-8ba2-7142b76851cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# Load dataset with summaries\n",
    "file_path = \"/Volumes/ads-predictive-analytics/default/test/clinical_notes_with_rag_summaries.csv\"  \n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Initialize ROUGE scorer\n",
    "scorer = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True)\n",
    "\n",
    "#create function\n",
    "def evaluate_summary(reference, generated):\n",
    "    \"\"\"Compute ROUGE scores between reference (original) and generated summaries.\"\"\"\n",
    "    scores = scorer.score(reference, generated)\n",
    "    return {\n",
    "        \"ROUGE-1\": scores[\"rouge1\"].fmeasure,\n",
    "        \"ROUGE-2\": scores[\"rouge2\"].fmeasure,\n",
    "        \"ROUGE-L\": scores[\"rougeL\"].fmeasure,\n",
    "    }\n",
    "\n",
    "# Apply evaluation\n",
    "results = df.apply(lambda row: evaluate_summary(row[\"Notes\"], row[\"Generated_Summary\"]), axis=1)\n",
    "\n",
    "df_results = pd.DataFrame(list(results))\n",
    "\n",
    "df[\"ROUGE-1\"], df[\"ROUGE-2\"], df[\"ROUGE-L\"] = df_results[\"ROUGE-1\"], df_results[\"ROUGE-2\"], df_results[\"ROUGE-L\"]\n",
    "\n",
    "# Save evaluation results\n",
    "output_file = \"/Volumes/ads-predictive-analytics/default/test/evaluated_summaries.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "# Print average scores\n",
    "print(\"Average ROUGE Scores:\")\n",
    "print(df_results.mean())\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Clinical Note Summarizations",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
